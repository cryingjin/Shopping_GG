{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2302,
     "status": "ok",
     "timestamp": 1600345659765,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "_HNtAJOnCYaX"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1388,
     "status": "ok",
     "timestamp": 1600345659770,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "T_IJyucOZ6JU",
    "outputId": "1d5c196a-318e-4fa4-ddec-bd45bbb6f216"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 775,
     "status": "ok",
     "timestamp": 1600345661229,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "W_NDYqsBwKai"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3_f-xCHwNCD"
   },
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6310,
     "status": "ok",
     "timestamp": 1600345675129,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "90j6-1GpuNr_"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "data = joblib.load('./train_FE.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5024,
     "status": "ok",
     "timestamp": 1600345675131,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "j_9H_Hvsudap"
   },
   "outputs": [],
   "source": [
    "locals().update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4685,
     "status": "ok",
     "timestamp": 1600345675132,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "_OrlKfnaue6_"
   },
   "outputs": [],
   "source": [
    "X = data['X']\n",
    "y =data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4387,
     "status": "ok",
     "timestamp": 1600345675133,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "TDibtKW_vaBu",
    "outputId": "9ebe6633-137d-444f-a9aa-d3cdef6cbbbc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>노출(분)</th>\n",
       "      <th>판매단가</th>\n",
       "      <th>NEW_최고판매단가</th>\n",
       "      <th>NEW_최저판매단가</th>\n",
       "      <th>NEW_중간판매단가</th>\n",
       "      <th>NEW_최고-최저</th>\n",
       "      <th>상품군_최고판매단가</th>\n",
       "      <th>상품군_최저판매단가</th>\n",
       "      <th>상품군_중간판매단가</th>\n",
       "      <th>상품군_최고-최저</th>\n",
       "      <th>...</th>\n",
       "      <th>방송시간대_오후</th>\n",
       "      <th>방송시간대_저녁</th>\n",
       "      <th>계절_가을</th>\n",
       "      <th>계절_겨울</th>\n",
       "      <th>계절_봄</th>\n",
       "      <th>계절_여름</th>\n",
       "      <th>분기_1분기</th>\n",
       "      <th>분기_2분기</th>\n",
       "      <th>분기_3분기</th>\n",
       "      <th>분기_4분기</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39900</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2490000</td>\n",
       "      <td>29000</td>\n",
       "      <td>69000</td>\n",
       "      <td>2461000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39900</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2490000</td>\n",
       "      <td>29000</td>\n",
       "      <td>69000</td>\n",
       "      <td>2461000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39900</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2490000</td>\n",
       "      <td>29000</td>\n",
       "      <td>69000</td>\n",
       "      <td>2461000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39900</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2490000</td>\n",
       "      <td>29000</td>\n",
       "      <td>69000</td>\n",
       "      <td>2461000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39900</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>39900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2490000</td>\n",
       "      <td>29000</td>\n",
       "      <td>69000</td>\n",
       "      <td>2461000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38299</td>\n",
       "      <td>20.0</td>\n",
       "      <td>148000</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>148000.0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1184400</td>\n",
       "      <td>24900</td>\n",
       "      <td>158000</td>\n",
       "      <td>1159500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38300</td>\n",
       "      <td>20.0</td>\n",
       "      <td>178000</td>\n",
       "      <td>178000.0</td>\n",
       "      <td>168000.0</td>\n",
       "      <td>173000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1184400</td>\n",
       "      <td>24900</td>\n",
       "      <td>158000</td>\n",
       "      <td>1159500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38301</td>\n",
       "      <td>20.0</td>\n",
       "      <td>168000</td>\n",
       "      <td>178000.0</td>\n",
       "      <td>168000.0</td>\n",
       "      <td>173000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1184400</td>\n",
       "      <td>24900</td>\n",
       "      <td>158000</td>\n",
       "      <td>1159500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38302</td>\n",
       "      <td>20.0</td>\n",
       "      <td>158000</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>148000.0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1184400</td>\n",
       "      <td>24900</td>\n",
       "      <td>158000</td>\n",
       "      <td>1159500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38303</td>\n",
       "      <td>20.0</td>\n",
       "      <td>148000</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>148000.0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1184400</td>\n",
       "      <td>24900</td>\n",
       "      <td>158000</td>\n",
       "      <td>1159500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35379 rows × 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       노출(분)    판매단가  NEW_최고판매단가  NEW_최저판매단가  NEW_중간판매단가  NEW_최고-최저  \\\n",
       "0       20.0   39900     39900.0     39900.0     39900.0        0.0   \n",
       "1       20.0   39900     39900.0     39900.0     39900.0        0.0   \n",
       "2       20.0   39900     39900.0     39900.0     39900.0        0.0   \n",
       "3       20.0   39900     39900.0     39900.0     39900.0        0.0   \n",
       "4       20.0   39900     39900.0     39900.0     39900.0        0.0   \n",
       "...      ...     ...         ...         ...         ...        ...   \n",
       "38299   20.0  148000    158000.0    148000.0    153000.0    10000.0   \n",
       "38300   20.0  178000    178000.0    168000.0    173000.0    10000.0   \n",
       "38301   20.0  168000    178000.0    168000.0    173000.0    10000.0   \n",
       "38302   20.0  158000    158000.0    148000.0    153000.0    10000.0   \n",
       "38303   20.0  148000    158000.0    148000.0    153000.0    10000.0   \n",
       "\n",
       "       상품군_최고판매단가  상품군_최저판매단가  상품군_중간판매단가  상품군_최고-최저  ...  방송시간대_오후  방송시간대_저녁  \\\n",
       "0         2490000       29000       69000    2461000  ...         0         0   \n",
       "1         2490000       29000       69000    2461000  ...         0         0   \n",
       "2         2490000       29000       69000    2461000  ...         0         0   \n",
       "3         2490000       29000       69000    2461000  ...         0         0   \n",
       "4         2490000       29000       69000    2461000  ...         0         0   \n",
       "...           ...         ...         ...        ...  ...       ...       ...   \n",
       "38299     1184400       24900      158000    1159500  ...         0         0   \n",
       "38300     1184400       24900      158000    1159500  ...         0         0   \n",
       "38301     1184400       24900      158000    1159500  ...         0         0   \n",
       "38302     1184400       24900      158000    1159500  ...         0         0   \n",
       "38303     1184400       24900      158000    1159500  ...         0         0   \n",
       "\n",
       "       계절_가을  계절_겨울  계절_봄  계절_여름  분기_1분기  분기_2분기  분기_3분기  분기_4분기  \n",
       "0          0      1     0      0       1       0       0       0  \n",
       "1          0      1     0      0       1       0       0       0  \n",
       "2          0      1     0      0       1       0       0       0  \n",
       "3          0      1     0      0       1       0       0       0  \n",
       "4          0      1     0      0       1       0       0       0  \n",
       "...      ...    ...   ...    ...     ...     ...     ...     ...  \n",
       "38299      0      1     0      0       0       0       0       1  \n",
       "38300      0      1     0      0       0       0       0       1  \n",
       "38301      0      1     0      0       0       0       0       1  \n",
       "38302      0      1     0      0       0       0       0       1  \n",
       "38303      0      1     0      0       0       0       0       1  \n",
       "\n",
       "[35379 rows x 401 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4190,
     "status": "ok",
     "timestamp": 1600345675134,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "aVp5V40vVrd0"
   },
   "outputs": [],
   "source": [
    "gnt = ['판매단가',\\\n",
    "'방송월',\\\n",
    "'방송일',\\\n",
    "'상품군별월별평균판매량',\\\n",
    "'상품군별시간대별평균판매량',\\\n",
    "'상품군별시간분별평균판매량',\\\n",
    "'할인율','상품군_zscore',\\\n",
    "'상품군&브랜드_zscore',\\\n",
    "'마더코드_zscore',\\\n",
    "'NEW_zscore',\\\n",
    "'pca_1',\\\n",
    "'pca_2',\\\n",
    "'강수량(mm)_서울',\\\n",
    "'기온(°C)_서울',\\\n",
    "'습도(%)_서울',\\\n",
    "'시정(10m)_서울',\\\n",
    "'지면온도(°C)_서울',\\\n",
    "'체감온도_서울',\\\n",
    "'풍속(m/s)_서울',\\\n",
    "'최고PM10_서울',\n",
    "'상품군_가구',\\\n",
    "'상품군_가전',\\\n",
    "'상품군_건강기능',\\\n",
    "'상품군_농수축',\\\n",
    "'상품군_생활용품',\\\n",
    "'상품군_속옷',\\\n",
    "'상품군_의류',\\\n",
    "'상품군_이미용',\\\n",
    "'상품군_잡화',\\\n",
    "'상품군_주방',\\\n",
    "'상품군_침구']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2796,
     "status": "ok",
     "timestamp": 1600345675135,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "8LlTF8J9ZHWd"
   },
   "outputs": [],
   "source": [
    "column_list =[]\n",
    "for col in X.columns:\n",
    "    column_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 931,
     "status": "ok",
     "timestamp": 1600345725580,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "URmvwRxG9Ho7"
   },
   "outputs": [],
   "source": [
    "emb_list = ['v'+str(j) for j in range(0,110)]\n",
    "for i in emb_list:\n",
    "  column_list.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1560,
     "status": "ok",
     "timestamp": 1600345726729,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "Yr_erm5p9ppZ"
   },
   "outputs": [],
   "source": [
    "num_list = column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2010,
     "status": "ok",
     "timestamp": 1600345727529,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "T-TbhgJ6CZm8"
   },
   "outputs": [],
   "source": [
    "X_origin = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1087,
     "status": "ok",
     "timestamp": 1600345751074,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "V5C3tQiIQ6R7"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "X_c = X.copy()\n",
    "scaler = MinMaxScaler()\n",
    "X_c = scaler.fit_transform(X_c)\n",
    "X_tmp = pd.DataFrame(X_c, columns=X.columns, index=list(X.index.values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 807,
     "status": "ok",
     "timestamp": 1600345755676,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "U6zpkbEW4684"
   },
   "outputs": [],
   "source": [
    "X_num = X_tmp[column_list]\n",
    "X_emb = X_tmp[emb_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1600345756119,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "z0xj1JDcawUT"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_num = X_num.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1441,
     "status": "ok",
     "timestamp": 1600345757791,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "sV1n5SSr-a6y"
   },
   "outputs": [],
   "source": [
    "#X = pd.read_excel(\"0906_notD.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1148,
     "status": "ok",
     "timestamp": 1600345758156,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "tIFcFeED-SVN",
    "outputId": "dcb7135f-66d8-42e9-a0dc-fe95f0de30e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 35379 entries, 0 to 38303\n",
      "Columns: 291 entries, 노출(분) to 분기_4분기\n",
      "dtypes: float64(291)\n",
      "memory usage: 78.8 MB\n"
     ]
    }
   ],
   "source": [
    "X_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 791,
     "status": "ok",
     "timestamp": 1600345758158,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "kJbh0NTkg4aQ",
    "outputId": "1f8251af-0926-4d57-9736-d14255418d3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 35379 entries, 0 to 38303\n",
      "Columns: 110 entries, v0 to v109\n",
      "dtypes: float64(110)\n",
      "memory usage: 30.0 MB\n"
     ]
    }
   ],
   "source": [
    "X_emb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u06H2tY4wTNM"
   },
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 750,
     "status": "ok",
     "timestamp": 1600345764728,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "rpKfv7HK4bdn"
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 954,
     "status": "ok",
     "timestamp": 1600345765859,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "tq1EbmD6Pkua",
    "outputId": "88418188-aa50-4c00-9b45-8474b7ea6edd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfilename = 'checkpoint-epoch-{}-batch-{}-trial-001.h5'.format(EPOCH, BATCH_SIZE)\\ncheckpoint = ModelCheckpoint(filename,             # file명을 지정합니다\\n                             monitor='val_loss',   # val_loss 값이 개선되었을때 호출됩니다\\n                             verbose=1,            # 로그를 출력합니다\\n                             save_best_only=True,  # 가장 best 값만 저장합니다\\n                             mode='auto'           # auto는 알아서 best를 찾습니다. min/max\\n                            )\\n                            \""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "reduceLR = ReduceLROnPlateau( \n",
    "    monitor='loss',  # 모니터 기준 설정 val_loss? val_acc?\n",
    "    factor=0.5,          # callback 호출시 학습률을 1/2로 줄인다\n",
    "    patience=10,         # epoch 10 동안 개선되지 않으면 callback이 호출\n",
    ")\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='loss',  # 모니터 기준 설정 (val_loss) \n",
    "                              patience=100,         # 15회 Epoch동안 개선되지 않는다면 종료\n",
    "                             )\n",
    "\"\"\"\n",
    "filename = 'checkpoint-epoch-{}-batch-{}-trial-001.h5'.format(EPOCH, BATCH_SIZE)\n",
    "checkpoint = ModelCheckpoint(filename,             # file명을 지정합니다\n",
    "                             monitor='val_loss',   # val_loss 값이 개선되었을때 호출됩니다\n",
    "                             verbose=1,            # 로그를 출력합니다\n",
    "                             save_best_only=True,  # 가장 best 값만 저장합니다\n",
    "                             mode='auto'           # auto는 알아서 best를 찾습니다. min/max\n",
    "                            )\n",
    "                            \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xyt_J9Cok2US"
   },
   "source": [
    "## Multi input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1607,
     "status": "ok",
     "timestamp": 1600345767811,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "O9kAWsf6Ih_f"
   },
   "outputs": [],
   "source": [
    "\n",
    "#define loss \n",
    "\n",
    "def mean_absolute_percentage_error_ours(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.math.abs((tf.math.exp(y_true) - tf.math.exp(y_pred)) / tf.math.exp(y_true)))* 100\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "  y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1600345768180,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "Ls83-9C9zzVH"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_mlp(dim, regress=False):\n",
    "\t# define our MLP network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=dim, activation ='relu', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, activation ='relu', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation ='relu', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation ='relu', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \"\"\"\n",
    "    model.add(Dense(128, input_dim=dim, activation ='relu', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, activation ='relu', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation ='relu', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \"\"\"\n",
    "    #model.add(Dense(64, activation ='relu', kernel_initializer='he_normal'))\n",
    "    #model.add(Dense(10, activation=\"LeakyReLU\"))\n",
    "    return model\n",
    "\n",
    "def create_1Dcnn(dim):\n",
    "    inputShape = (dim,1)\n",
    "\n",
    "    Inputs = Input(shape = inputShape)\n",
    "\n",
    "    conv1 = Conv1D(filters = 16, kernel_size=6,padding = 'valid',activation ='linear', kernel_initializer='he_normal')(Inputs)\n",
    "    pool1 = GlobalAveragePooling1D()(conv1)\n",
    "\n",
    "    conv2 = Conv1D(filters = 16, kernel_size=7,padding = 'valid', activation ='linear', kernel_initializer='he_normal')(Inputs)\n",
    "    pool2 = GlobalAveragePooling1D()(conv2)\n",
    "\n",
    "    conv3 = Conv1D(filters = 16, kernel_size=8,padding = 'valid', activation ='linear', kernel_initializer='he_normal')(Inputs)\n",
    "    pool3 = GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    concat = concatenate([pool1, pool2, pool3])\n",
    "    #concat = tf.expand_dims(concat,-1)\n",
    "\n",
    "    #results = LSTM(64)(concat)\n",
    "    results = Dense(10,activation ='linear', kernel_initializer='he_normal')(concat)\n",
    "    model = Model(Inputs,results)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_lstm(dim):\n",
    "    inputShape = (dim,1)\n",
    "    \n",
    "    inputs = Input(shape = inputShape)\n",
    "    print(inputs.shape)\n",
    "    \n",
    "    x = LSTM(20, return_sequences=True,kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(10,kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(10,activation ='relu', kernel_initializer='he_normal')(x)\n",
    "    model = Model(inputs,x)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1463,
     "status": "ok",
     "timestamp": 1600345768774,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "LNq_J9hqL2gC",
    "outputId": "fcb1fb18-ca44-4e08-a0c2-011257dbe1cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35379, 291)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8919,
     "status": "ok",
     "timestamp": 1600345776483,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "ndyKXZvO5QOX",
    "outputId": "73c27184-c91d-47ea-cbd2-1e9b74f6b01a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 291, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_num_lstm = X_num.copy() \n",
    "X_num_lstm = np.array(X_num_lstm)\n",
    "X_num_lstm = np.reshape(X_num_lstm,(X_num_lstm.shape[0],X_num_lstm.shape[1],1))\n",
    "# create the MLP and LSTM models\n",
    "mlp = create_mlp(X_num.shape[1], regress=False)\n",
    "cnn = create_1Dcnn(X_emb.shape[1])\n",
    "lstm = create_lstm((X_num.shape[1]))\n",
    "#print(mlp.output, lstm.output)\n",
    "\n",
    "combinedInput = concatenate([lstm.output, cnn.output])\n",
    "#combinedInput = tf.expand_dims(combinedInput,-1)\n",
    "\n",
    "# our final FC layer head will have two dense layers, the final one\n",
    "# being our regression head\n",
    "#x = LSTM(5)(combinedInput)\n",
    "\n",
    "x = Dense(32, activation=\"selu\")(combinedInput)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(8, activation=\"selu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(1, activation=\"selu\")(x)\n",
    "\n",
    "model = Model(inputs=[lstm.input, cnn.input], outputs=x)\n",
    "\n",
    "\n",
    "opt = Adam(lr=0.00001, decay=1e-3 / 200)\n",
    "#opt = RMSprop(0.001)\n",
    "model.compile(loss= \"mean_absolute_percentage_error\",optimizer=opt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 852
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7992,
     "status": "ok",
     "timestamp": 1600345776485,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "6IaxMDDmHoq_",
    "outputId": "11debf86-59a1-43dc-fd41-1aea9cba0535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_59\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           [(None, 291, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_25 (LSTM)                  (None, 291, 20)      1760        input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 291, 20)      80          lstm_25[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 291, 20)      0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           [(None, 110, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_26 (LSTM)                  (None, 10)           1240        dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 105, 16)      112         input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 104, 16)      128         input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 103, 16)      144         input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 10)           40          lstm_26[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_27 (Gl (None, 16)           0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_28 (Gl (None, 16)           0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_29 (Gl (None, 16)           0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 10)           0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 48)           0           global_average_pooling1d_27[0][0]\n",
      "                                                                 global_average_pooling1d_28[0][0]\n",
      "                                                                 global_average_pooling1d_29[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 10)           110         dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 10)           490         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 20)           0           dense_85[0][0]                   \n",
      "                                                                 dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 32)           672         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 32)           128         dense_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 32)           0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 8)            264         dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 8)            0           dense_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 1)            9           dropout_86[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 5,177\n",
      "Trainable params: 5,053\n",
      "Non-trainable params: 124\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i90WtzINkcWr"
   },
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6946,
     "status": "ok",
     "timestamp": 1600345776488,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "zDSU_sU7QFdb",
    "outputId": "eeeff5cc-60a9-45c3-fb3e-283936204c14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>노출(분)</th>\n",
       "      <th>판매단가</th>\n",
       "      <th>NEW_최고판매단가</th>\n",
       "      <th>NEW_최저판매단가</th>\n",
       "      <th>NEW_중간판매단가</th>\n",
       "      <th>NEW_최고-최저</th>\n",
       "      <th>상품군_최고판매단가</th>\n",
       "      <th>상품군_최저판매단가</th>\n",
       "      <th>상품군_중간판매단가</th>\n",
       "      <th>상품군_최고-최저</th>\n",
       "      <th>...</th>\n",
       "      <th>방송시간대_오후</th>\n",
       "      <th>방송시간대_저녁</th>\n",
       "      <th>계절_가을</th>\n",
       "      <th>계절_겨울</th>\n",
       "      <th>계절_봄</th>\n",
       "      <th>계절_여름</th>\n",
       "      <th>분기_1분기</th>\n",
       "      <th>분기_2분기</th>\n",
       "      <th>분기_3분기</th>\n",
       "      <th>분기_4분기</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.46714</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307015</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.019944</td>\n",
       "      <td>0.307967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.46714</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307015</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.019944</td>\n",
       "      <td>0.307967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.46714</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307015</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.019944</td>\n",
       "      <td>0.307967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.46714</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307015</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.019944</td>\n",
       "      <td>0.307967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.46714</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307015</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.019944</td>\n",
       "      <td>0.307967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38299</td>\n",
       "      <td>0.46714</td>\n",
       "      <td>0.017077</td>\n",
       "      <td>0.018340</td>\n",
       "      <td>0.017077</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.140699</td>\n",
       "      <td>0.080026</td>\n",
       "      <td>0.080940</td>\n",
       "      <td>0.142401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38300</td>\n",
       "      <td>0.46714</td>\n",
       "      <td>0.020866</td>\n",
       "      <td>0.020866</td>\n",
       "      <td>0.019603</td>\n",
       "      <td>0.020234</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.140699</td>\n",
       "      <td>0.080026</td>\n",
       "      <td>0.080940</td>\n",
       "      <td>0.142401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38301</td>\n",
       "      <td>0.46714</td>\n",
       "      <td>0.019603</td>\n",
       "      <td>0.020866</td>\n",
       "      <td>0.019603</td>\n",
       "      <td>0.020234</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.140699</td>\n",
       "      <td>0.080026</td>\n",
       "      <td>0.080940</td>\n",
       "      <td>0.142401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38302</td>\n",
       "      <td>0.46714</td>\n",
       "      <td>0.018340</td>\n",
       "      <td>0.018340</td>\n",
       "      <td>0.017077</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.140699</td>\n",
       "      <td>0.080026</td>\n",
       "      <td>0.080940</td>\n",
       "      <td>0.142401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38303</td>\n",
       "      <td>0.46714</td>\n",
       "      <td>0.017077</td>\n",
       "      <td>0.018340</td>\n",
       "      <td>0.017077</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.140699</td>\n",
       "      <td>0.080026</td>\n",
       "      <td>0.080940</td>\n",
       "      <td>0.142401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35379 rows × 291 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         노출(분)      판매단가  NEW_최고판매단가  NEW_최저판매단가  NEW_중간판매단가  NEW_최고-최저  \\\n",
       "0      0.46714  0.003423    0.003423    0.003423    0.003423   0.000000   \n",
       "1      0.46714  0.003423    0.003423    0.003423    0.003423   0.000000   \n",
       "2      0.46714  0.003423    0.003423    0.003423    0.003423   0.000000   \n",
       "3      0.46714  0.003423    0.003423    0.003423    0.003423   0.000000   \n",
       "4      0.46714  0.003423    0.003423    0.003423    0.003423   0.000000   \n",
       "...        ...       ...         ...         ...         ...        ...   \n",
       "38299  0.46714  0.017077    0.018340    0.017077    0.017708   0.016949   \n",
       "38300  0.46714  0.020866    0.020866    0.019603    0.020234   0.016949   \n",
       "38301  0.46714  0.019603    0.020866    0.019603    0.020234   0.016949   \n",
       "38302  0.46714  0.018340    0.018340    0.017077    0.017708   0.016949   \n",
       "38303  0.46714  0.017077    0.018340    0.017077    0.017708   0.016949   \n",
       "\n",
       "       상품군_최고판매단가  상품군_최저판매단가  상품군_중간판매단가  상품군_최고-최저  ...  방송시간대_오후  방송시간대_저녁  \\\n",
       "0        0.307015    0.107143    0.019944   0.307967  ...       0.0       0.0   \n",
       "1        0.307015    0.107143    0.019944   0.307967  ...       0.0       0.0   \n",
       "2        0.307015    0.107143    0.019944   0.307967  ...       0.0       0.0   \n",
       "3        0.307015    0.107143    0.019944   0.307967  ...       0.0       0.0   \n",
       "4        0.307015    0.107143    0.019944   0.307967  ...       0.0       0.0   \n",
       "...           ...         ...         ...        ...  ...       ...       ...   \n",
       "38299    0.140699    0.080026    0.080940   0.142401  ...       0.0       0.0   \n",
       "38300    0.140699    0.080026    0.080940   0.142401  ...       0.0       0.0   \n",
       "38301    0.140699    0.080026    0.080940   0.142401  ...       0.0       0.0   \n",
       "38302    0.140699    0.080026    0.080940   0.142401  ...       0.0       0.0   \n",
       "38303    0.140699    0.080026    0.080940   0.142401  ...       0.0       0.0   \n",
       "\n",
       "       계절_가을  계절_겨울  계절_봄  계절_여름  분기_1분기  분기_2분기  분기_3분기  분기_4분기  \n",
       "0        0.0    1.0   0.0    0.0     1.0     0.0     0.0     0.0  \n",
       "1        0.0    1.0   0.0    0.0     1.0     0.0     0.0     0.0  \n",
       "2        0.0    1.0   0.0    0.0     1.0     0.0     0.0     0.0  \n",
       "3        0.0    1.0   0.0    0.0     1.0     0.0     0.0     0.0  \n",
       "4        0.0    1.0   0.0    0.0     1.0     0.0     0.0     0.0  \n",
       "...      ...    ...   ...    ...     ...     ...     ...     ...  \n",
       "38299    0.0    1.0   0.0    0.0     0.0     0.0     0.0     1.0  \n",
       "38300    0.0    1.0   0.0    0.0     0.0     0.0     0.0     1.0  \n",
       "38301    0.0    1.0   0.0    0.0     0.0     0.0     0.0     1.0  \n",
       "38302    0.0    1.0   0.0    0.0     0.0     0.0     0.0     1.0  \n",
       "38303    0.0    1.0   0.0    0.0     0.0     0.0     0.0     1.0  \n",
       "\n",
       "[35379 rows x 291 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6227,
     "status": "ok",
     "timestamp": 1600345776490,
     "user": {
      "displayName": "shin minjung",
      "photoUrl": "",
      "userId": "09743716370324277104"
     },
     "user_tz": -540
    },
    "id": "hMrJ2Lfq6_HY"
   },
   "outputs": [],
   "source": [
    "y = data['y']\n",
    "#y = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OcDUuSkSkfyY",
    "outputId": "9e405c59-44a1-4a12-be5d-75f6b4ebf8d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리중인 fold: 1\n",
      "(32614, 291, 1) (32614, 110, 1) (32614,)\n",
      "(2707, 291, 1) (2707, 110, 1) (2707,)\n",
      "(0, 291, 1) (0, 110, 1) (0,)\n",
      "Epoch 1/2000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 2/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 3/2000\n",
      "128/128 [==============================] - ETA: 0s - loss: 100.000 - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 4/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 5/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 6/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 7/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 8/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 9/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 10/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 11/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 12/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 13/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 14/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 15/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 16/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 17/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 18/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 19/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 20/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 21/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 22/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 23/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 24/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 25/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 26/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 27/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 28/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 29/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 30/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 31/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 32/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 33/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 34/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 35/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 36/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 37/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 38/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 39/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 40/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 41/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 42/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 43/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 44/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 45/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 46/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 47/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 48/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 49/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 50/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 51/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 52/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 53/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 54/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 55/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 56/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 57/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 58/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 59/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 60/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 61/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 62/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 63/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 64/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 65/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 66/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 67/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 68/2000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 69/2000\n",
      "128/128 [==============================] - 4s 31ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 70/2000\n",
      "128/128 [==============================] - 4s 32ms/step - loss: 100.0000 - val_loss: 100.0000\n",
      "Epoch 71/2000\n",
      " 73/128 [================>.............] - ETA: 1s - loss: 100.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-daf48ddfd549>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_val_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val_emb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     callbacks = [reduceLR,earlystopping])\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_emb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preds = {'val_preds' : [], 'test_preds' : []} \n",
    "mape = {'val_mape' : [], 'test_mape' : []} \n",
    "\n",
    "for i in range(1,13):\n",
    "    print('처리중인 fold:',i)\n",
    "\n",
    "    train_idx = X[X['방송월'] != i ].index\n",
    "    test_idx = X[X['방송월'] == i ].index\n",
    "\n",
    "    X_train_num = X_num.loc[train_idx]\n",
    "    X_train_emb = X_emb.loc[train_idx]\n",
    "    y_train = y.loc[X_train_num.index]\n",
    "\n",
    "\n",
    "    test_num = X_num.loc[test_idx]\n",
    "    test_emb = X_emb.loc[test_idx]\n",
    "\n",
    "    X_val_num = test_num.loc[((test_num['방송일'] > 0) & (test_num['방송일'] <15))]\n",
    "    X_val_emb = test_emb.loc[X_val_num.index]\n",
    "    y_val = y.loc[X_val_num.index]\n",
    "\n",
    "    X_test_num = test_num.loc[((test_num['방송일'] > 16) & (test_num['방송일'] < 32))]\n",
    "    X_test_emb = test_emb.loc[X_test_num.index]\n",
    "    y_test = y.loc[X_test_num.index]\n",
    "\n",
    "\n",
    "    X_train_emb = np.asarray(X_train_emb).astype(np.float32)\n",
    "    X_train_emb = np.reshape(X_train_emb,(X_train_emb.shape[0],X_train_emb.shape[1],1))\n",
    "\n",
    "    X_train_num = np.asarray(X_train_num).astype(np.float32)\n",
    "    X_train_num = np.reshape(X_train_num,(X_train_num.shape[0],X_train_num.shape[1],1))\n",
    "\n",
    "    y_train = np.asarray(y_train).astype(np.float32)\n",
    "\n",
    "    X_test_emb = np.asarray(X_test_emb).astype(np.float32)\n",
    "    X_test_emb = np.reshape(X_test_emb,(X_test_emb.shape[0],X_test_emb.shape[1],1))\n",
    "    X_test_num = np.asarray(X_test_num).astype(np.float32)\n",
    "    X_test_num = np.reshape(X_test_num,(X_test_num.shape[0],X_test_num.shape[1],1))\n",
    "\n",
    "    y_test = np.asarray(y_test).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    X_val_emb = np.asarray(X_val_emb).astype(np.float32)\n",
    "    X_val_emb = np.reshape(X_val_emb,(X_val_emb.shape[0],X_val_emb.shape[1],1))\n",
    "    X_val_num = np.asarray(X_val_num).astype(np.float32)\n",
    "    X_val_num = np.reshape(X_val_num,(X_val_num.shape[0],X_val_num.shape[1],1))\n",
    "\n",
    "    y_val = np.asarray(y_val).astype(np.float32)\n",
    "    print(X_train_num.shape, X_train_emb.shape, y_train.shape)\n",
    "    print(X_val_num.shape, X_val_emb.shape, y_val.shape)\n",
    "    print(X_test_num.shape, X_test_emb.shape, y_test.shape)\n",
    "    model.fit(\n",
    "    x=[X_train_num, X_train_emb], y=y_train,\n",
    "    validation_data=([X_val_num, X_val_emb], y_val),\n",
    "    epochs=2000, batch_size = 256,\n",
    "    callbacks = [reduceLR,earlystopping])\n",
    "\n",
    "    y_pred = model.predict([X_test_num, X_test_emb])\n",
    "    val_pred = model.predict([X_val_num, X_val_emb])\n",
    "    \n",
    "    preds['val_preds'].append(val_pred)\n",
    "    preds['test_preds'].append(y_pred)\n",
    "    mape['val_mape'].append(mean_absolute_percentage_error(y_val, val_pred))\n",
    "    mape['test_mape'].append(mean_absolute_percentage_error(y_test,y_pred))\n",
    "    \"\"\"\n",
    "\n",
    "    preds['val_preds'].append(np.exp(val_pred))\n",
    "    preds['test_preds'].append(np.exp(y_pred))\n",
    "    mape['val_mape'].append(mean_absolute_percentage_error(np.exp(y_val), np.exp(val_pred)))\n",
    "    mape['test_mape'].append(mean_absolute_percentage_error(np.exp(y_test), np.exp(y_pred)))\n",
    "    \"\"\"\n",
    "    for m, arg in enumerate(zip(mape['val_mape'], mape['test_mape']), 1):\n",
    "            print(f'{m}월\\t', '[val]:', arg[0], '\\t[test]', arg[1]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTO9A1CawQXR"
   },
   "source": [
    "최종 Model MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "--7f7FQas0EU"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.plot(mape['val_mape'])\n",
    "plt.plot(mape['test_mape'])\n",
    "plt.xlabel('Month', fontsize = 14)\n",
    "plt.title('MAPE', fontsize = 15)\n",
    "plt.legend(['valid', 'test'])\n",
    "plt.xticks(np.arange(0,12), np.arange(1,13))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4W1GWHJ_Sfl"
   },
   "outputs": [],
   "source": [
    "print(mape['val_mape'])\n",
    "print(mape['test_mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MTIUNK-SthyY"
   },
   "outputs": [],
   "source": [
    " np.mean(mape['val_mape']), np.mean(mape['test_mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8ev85k8_dxg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "feature줄인버전MMscaling.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
