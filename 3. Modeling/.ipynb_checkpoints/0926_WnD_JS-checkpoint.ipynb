{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import random\n",
    "import joblib\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data = joblib.load(os.path.join('..', '..', '0.Data', '05_분석데이터', 'data4WnD.pkl'))\n",
    "locals().update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sas = joblib.load(os.path.join('..', '..', '0.Data', '05_분석데이터', 'prep4sas.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train = pd.read_excel(os.path.join('..', '..', '0.Data', '01_제공데이터', '2020 빅콘테스트 데이터분석분야-챔피언리그_2019년 실적데이터_v1_200818.xlsx'), skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train['취급액'] = train['취급액'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train = train.loc[(train['상품군'] != '무형') & (train['취급액'] != -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train = train.merge(sas['item'], on = '마더코드', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "label = np.array([np.zeros(sas['item']['index'].max(), dtype=np.int32) for _ in range(train.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for l, idx in zip(label, train['index'].values):\n",
    "    l[idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from keras.layers import Input, Embedding, Dense, Flatten, Dropout, SpatialDropout1D, Activation, concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers.advanced_activations import ReLU, PReLU, LeakyReLU, ELU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['isHoliday', '평일여부', '방송시간대', '계절', '분기']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "CONTINUOUS_COLUMNS = ['방송월',\n",
    " '방송일',\n",
    " '방송시간(시간)',\n",
    " '방송시간(분)',\n",
    " '합계',\n",
    " '컴퓨터 및 주변기기',\n",
    " '가전·전자·통신기기',\n",
    " '서적',\n",
    " '사무·문구',\n",
    " '의복',\n",
    " '신발',\n",
    " '가방',\n",
    " '패션용품 및 액세서리',\n",
    " '스포츠·레저용품',\n",
    " '화장품',\n",
    " '아동·유아용품',\n",
    " '음·식료품',\n",
    " '농축수산물',\n",
    " '생활용품',\n",
    " '자동차 및 자동차용품',\n",
    " '가구',\n",
    " '애완용품',\n",
    " '여행 및 교통서비스',\n",
    " '문화 및 레저서비스',\n",
    " 'e쿠폰서비스',\n",
    " '음식서비스',\n",
    " '기타서비스',\n",
    " '기타',\n",
    " '현재생활형편CSI',\n",
    " '현재경기판단CSI',\n",
    " '생활형편전망CSI',\n",
    " '소비지출전망CSI',\n",
    " '주택가격전망CSI',\n",
    " '임금수준전망CSI',\n",
    " '소비자심리지수',\n",
    " '경상지수',\n",
    " '불변지수',\n",
    " 'pca_1',\n",
    " 'pca_2',\n",
    " 'pca_3',\n",
    " 'pca_4',\n",
    " 'pca_5',\n",
    " '강수량(mm)_경기',\n",
    " '강수량(mm)_광주',\n",
    " '강수량(mm)_대구',\n",
    " '강수량(mm)_대전',\n",
    " '강수량(mm)_부산',\n",
    " '강수량(mm)_서울',\n",
    " '강수량(mm)_울산',\n",
    " '강수량(mm)_인천',\n",
    " '기온(°C)_경기',\n",
    " '기온(°C)_광주',\n",
    " '기온(°C)_대구',\n",
    " '기온(°C)_대전',\n",
    " '기온(°C)_부산',\n",
    " '기온(°C)_서울',\n",
    " '기온(°C)_울산',\n",
    " '기온(°C)_인천',\n",
    " '습도(%)_경기',\n",
    " '습도(%)_광주',\n",
    " '습도(%)_대구',\n",
    " '습도(%)_대전',\n",
    " '습도(%)_부산',\n",
    " '습도(%)_서울',\n",
    " '습도(%)_울산',\n",
    " '습도(%)_인천',\n",
    " '시정(10m)_경기',\n",
    " '시정(10m)_광주',\n",
    " '시정(10m)_대구',\n",
    " '시정(10m)_대전',\n",
    " '시정(10m)_부산',\n",
    " '시정(10m)_서울',\n",
    " '시정(10m)_울산',\n",
    " '시정(10m)_인천',\n",
    " '지면온도(°C)_경기',\n",
    " '지면온도(°C)_광주',\n",
    " '지면온도(°C)_대구',\n",
    " '지면온도(°C)_대전',\n",
    " '지면온도(°C)_부산',\n",
    " '지면온도(°C)_서울',\n",
    " '지면온도(°C)_울산',\n",
    " '지면온도(°C)_인천',\n",
    " '체감온도_경기',\n",
    " '체감온도_광주',\n",
    " '체감온도_대구',\n",
    " '체감온도_대전',\n",
    " '체감온도_부산',\n",
    " '체감온도_서울',\n",
    " '체감온도_울산',\n",
    " '체감온도_인천',\n",
    " '풍속(m/s)_경기',\n",
    " '풍속(m/s)_광주',\n",
    " '풍속(m/s)_대구',\n",
    " '풍속(m/s)_대전',\n",
    " '풍속(m/s)_부산',\n",
    " '풍속(m/s)_서울',\n",
    " '풍속(m/s)_울산',\n",
    " '풍속(m/s)_인천',\n",
    " '최고PM10_경기',\n",
    " '최고PM10_광주',\n",
    " '최고PM10_대구',\n",
    " '최고PM10_대전',\n",
    " '최고PM10_부산',\n",
    " '최고PM10_서울',\n",
    " '최고PM10_울산',\n",
    " '최고PM10_인천',\n",
    " '최고PM25_경기',\n",
    " '최고PM25_광주',\n",
    " '최고PM25_대구',\n",
    " '최고PM25_대전',\n",
    " '최고PM25_부산',\n",
    " '최고PM25_서울',\n",
    " '최고PM25_울산',\n",
    " '최고PM25_인천',\n",
    " '최저PM10_경기',\n",
    " '최저PM10_광주',\n",
    " '최저PM10_대구',\n",
    " '최저PM10_대전',\n",
    " '최저PM10_부산',\n",
    " '최저PM10_서울',\n",
    " '최저PM10_울산',\n",
    " '최저PM10_인천',\n",
    " '최저PM25_경기',\n",
    " '최저PM25_광주',\n",
    " '최저PM25_대구',\n",
    " '최저PM25_대전',\n",
    " '최저PM25_부산',\n",
    " '최저PM25_서울',\n",
    " '최저PM25_울산',\n",
    " '최저PM25_인천',\n",
    " '평균PM10_경기',\n",
    " '평균PM10_광주',\n",
    " '평균PM10_대구',\n",
    " '평균PM10_대전',\n",
    " '평균PM10_부산',\n",
    " '평균PM10_서울',\n",
    " '평균PM10_울산',\n",
    " '평균PM10_인천',\n",
    " '평균PM25_경기',\n",
    " '평균PM25_광주',\n",
    " '평균PM25_대구',\n",
    " '평균PM25_대전',\n",
    " '평균PM25_부산',\n",
    " '평균PM25_서울',\n",
    " '평균PM25_울산',\n",
    " '평균PM25_인천']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "COLUMNS = CONTINUOUS_COLUMNS + CATEGORICAL_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def prep4WnD(train, test):\n",
    "    \n",
    "    x_train = train['X']\n",
    "    train_label = train['label']\n",
    "    train_size = len(x_train)\n",
    "    x_test = test['X']\n",
    "    test_label = test['label']\n",
    "    \n",
    "    data = pd.concat([x_train, x_test], axis = 0)\n",
    "    \n",
    "    X = data[COLUMNS]\n",
    "    \n",
    "    for c in CATEGORICAL_COLUMNS:\n",
    "        le = LabelEncoder()\n",
    "        X[c] = le.fit_transform(X[c])\n",
    "        \n",
    "    x_train = X.iloc[:train_size]\n",
    "    y_train = y[:train_size]\n",
    "    x_test = X.iloc[train_size:]\n",
    "    y_test = y[train_size:]\n",
    "    \n",
    "    x_train_category = np.array(x_train[CATEGORICAL_COLUMNS])\n",
    "    x_test_category = np.array(x_test[CATEGORICAL_COLUMNS])\n",
    "    x_train_continue = np.array(x_train[CONTINUOUS_COLUMNS], dtype='float64')\n",
    "    x_test_continue = np.array(x_test[CONTINUOUS_COLUMNS], dtype='float64')\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_continue_scaler = scaler.fit_transform(x_train_continue)\n",
    "    X_test_continue = scaler.transform(x_test_continue)\n",
    "    \n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "    x_train_category_poly = poly.fit_transform(x_train_category)\n",
    "    x_test_category_poly = poly.transform(x_test_category)\n",
    "    \n",
    "    data4train = (x_train_continue, x_train_category, x_train_category_poly, train_label)\n",
    "    data4test = (x_test_continue, x_test_category, x_test_category_poly, test_label)\n",
    "\n",
    "    return data4train, data4test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train = joblib.load(os.path.join('..', '..', '0.Data', '05_분석데이터', 'train_data4WnD.pkl'))\n",
    "test = joblib.load(os.path.join('..', '..', '0.Data', '05_분석데이터', 'test_data4WnD.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '아침'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-e05609c5687c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep4WnD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-198-1411bd9683c0>\u001b[0m in \u001b[0;36mprep4WnD\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mpoly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteraction_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mx_train_category_poly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_category\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mx_test_category_poly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_category\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1511\u001b[0m         \"\"\"\n\u001b[1;32m   1512\u001b[0m         n_samples, n_features = self._validate_data(\n\u001b[0;32m-> 1513\u001b[0;31m             X, accept_sparse=True).shape\n\u001b[0m\u001b[1;32m   1514\u001b[0m         combinations = self._combinations(n_features, self.degree,\n\u001b[1;32m   1515\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '아침'"
     ]
    }
   ],
   "source": [
    "a, b = prep4WnD(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X_category = np.array(X[CATEGORICAL_COLUMNS])\n",
    "X_continue = np.array(X[CONTINUOUS_COLUMNS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_continue_scaler = scaler.fit_transform(X_continue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_category_poly = poly.fit_transform(X_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_deep_model():\n",
    "\n",
    "    category_inputs = []\n",
    "    category_embeds = []\n",
    "    # 카테고리컬 데이터 임베딩\n",
    "    for i in range(len(CATEGORICAL_COLUMNS)):\n",
    "        input_i = Input(shape=(1,), dtype='int32')\n",
    "        dim = len(np.unique(data[CATEGORICAL_COLUMNS[i]]))\n",
    "        embed_dim = int(np.ceil(dim ** 0.5)) # embedding 차원을 0.5배 정도로 해서 한다.\n",
    "        embed_i = Embedding(dim, embed_dim, input_length=1)(input_i)\n",
    "        flatten_i = Flatten()(embed_i)\n",
    "        category_inputs.append(input_i)\n",
    "        category_embeds.append(flatten_i)\n",
    "    # continuous 데이터 input\n",
    "    continue_input = Input(shape=(len(CONTINUOUS_COLUMNS),))\n",
    "    continue_dense = Dense(256, use_bias=False)(continue_input)\n",
    "    # category와 continue를 합침\n",
    "    concat_embeds = concatenate([continue_dense] + category_embeds)\n",
    "    concat_embeds = Activation('relu')(concat_embeds)\n",
    "    bn_concat = BatchNormalization()(concat_embeds)\n",
    "\n",
    "    fc1 = Dense(512, use_bias=False)(bn_concat)\n",
    "    relu1 = ReLU()(fc1)\n",
    "    bn1 = BatchNormalization()(relu1)\n",
    "    fc2 = Dense(256, use_bias=False)(bn1)\n",
    "    relu2 = ReLU()(fc2)\n",
    "    bn2 = BatchNormalization()(relu2)\n",
    "    fc3 = Dense(128)(bn2)\n",
    "    relu3 = ReLU()(fc3)\n",
    "    \n",
    "    return category_inputs, continue_input, relu3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_wide_model():\n",
    "    dim = X_category_poly.shape[1]\n",
    "    return Input(shape=(dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "category_inputs, continue_input, deep_model = get_deep_model()\n",
    "wide_model = get_wide_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "out_layer = concatenate([deep_model, wide_model])\n",
    "inputs = [continue_input] + category_inputs + [wide_model]\n",
    "output = Dense(803, activation='softmax')(out_layer)\n",
    "model = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 146)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 2)         4           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 2)         4           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 3)         15          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 2)         8           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 2)         8           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          37376       input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 3)            0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 2)            0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 2)            0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 267)          0           dense_1[0][0]                    \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 267)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 267)          1068        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          136704      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512)          2048        re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          131072      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 256)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 128)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 144)          0           re_lu_3[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 803)          116435      concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 458,662\n",
      "Trainable params: 456,592\n",
      "Non-trainable params: 2,070\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "input_data = [X_continue] + [X_category[:, i] for i in range(X_category.shape[1])] + [X_category_poly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "optimizer ='adam'\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30072 samples, validate on 5307 samples\n",
      "Epoch 1/100\n",
      "30072/30072 [==============================] - 5s 151us/step - loss: 3.4793 - accuracy: 0.1333 - val_loss: 16.0382 - val_accuracy: 0.0179\n",
      "Epoch 2/100\n",
      "30072/30072 [==============================] - 4s 123us/step - loss: 3.3699 - accuracy: 0.1405 - val_loss: 17.4858 - val_accuracy: 0.0168\n",
      "Epoch 3/100\n",
      "30072/30072 [==============================] - 4s 125us/step - loss: 3.2974 - accuracy: 0.1493 - val_loss: 14.9847 - val_accuracy: 0.0228\n",
      "Epoch 4/100\n",
      "30072/30072 [==============================] - 4s 124us/step - loss: 3.2306 - accuracy: 0.1555 - val_loss: 22.8399 - val_accuracy: 0.0107\n",
      "Epoch 5/100\n",
      "30072/30072 [==============================] - 4s 137us/step - loss: 3.1611 - accuracy: 0.1657 - val_loss: 20.7644 - val_accuracy: 0.0313\n",
      "Epoch 6/100\n",
      "30072/30072 [==============================] - 4s 132us/step - loss: 3.1046 - accuracy: 0.1683 - val_loss: 23.9003 - val_accuracy: 0.0175\n",
      "Epoch 7/100\n",
      "30072/30072 [==============================] - 4s 134us/step - loss: 3.0521 - accuracy: 0.1761 - val_loss: 23.4068 - val_accuracy: 0.0215\n",
      "Epoch 8/100\n",
      "30072/30072 [==============================] - 4s 135us/step - loss: 2.9984 - accuracy: 0.1811 - val_loss: 21.8339 - val_accuracy: 0.0462\n",
      "Epoch 9/100\n",
      "30072/30072 [==============================] - 4s 126us/step - loss: 2.9456 - accuracy: 0.1879 - val_loss: 19.0338 - val_accuracy: 0.0187\n",
      "Epoch 10/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 2.8986 - accuracy: 0.1937 - val_loss: 23.7451 - val_accuracy: 0.0181\n",
      "Epoch 11/100\n",
      "30072/30072 [==============================] - 4s 136us/step - loss: 2.8548 - accuracy: 0.2006 - val_loss: 44.5955 - val_accuracy: 0.0070\n",
      "Epoch 12/100\n",
      "30072/30072 [==============================] - 4s 127us/step - loss: 2.8139 - accuracy: 0.2024 - val_loss: 38.5273 - val_accuracy: 0.0236\n",
      "Epoch 13/100\n",
      "30072/30072 [==============================] - 4s 134us/step - loss: 2.7697 - accuracy: 0.2091 - val_loss: 22.9228 - val_accuracy: 0.0153\n",
      "Epoch 14/100\n",
      "30072/30072 [==============================] - 4s 127us/step - loss: 2.7432 - accuracy: 0.2138 - val_loss: 27.5151 - val_accuracy: 0.0143\n",
      "Epoch 15/100\n",
      "30072/30072 [==============================] - 4s 136us/step - loss: 2.6940 - accuracy: 0.2239 - val_loss: 23.2735 - val_accuracy: 0.0200\n",
      "Epoch 16/100\n",
      "30072/30072 [==============================] - 4s 128us/step - loss: 2.6444 - accuracy: 0.2313 - val_loss: 27.4554 - val_accuracy: 0.0141\n",
      "Epoch 17/100\n",
      "30072/30072 [==============================] - 4s 126us/step - loss: 2.6006 - accuracy: 0.2420 - val_loss: 19.1319 - val_accuracy: 0.0275\n",
      "Epoch 18/100\n",
      "30072/30072 [==============================] - 4s 128us/step - loss: 2.5539 - accuracy: 0.2491 - val_loss: 22.4292 - val_accuracy: 0.0205\n",
      "Epoch 19/100\n",
      "30072/30072 [==============================] - 4s 131us/step - loss: 2.4886 - accuracy: 0.2621 - val_loss: 29.5945 - val_accuracy: 0.0079\n",
      "Epoch 20/100\n",
      "30072/30072 [==============================] - 4s 130us/step - loss: 2.4333 - accuracy: 0.2771 - val_loss: 23.7369 - val_accuracy: 0.0313\n",
      "Epoch 21/100\n",
      "30072/30072 [==============================] - 4s 130us/step - loss: 2.3875 - accuracy: 0.2813 - val_loss: 29.4758 - val_accuracy: 0.0170\n",
      "Epoch 22/100\n",
      "30072/30072 [==============================] - 4s 132us/step - loss: 2.3359 - accuracy: 0.2942 - val_loss: 22.0632 - val_accuracy: 0.0266\n",
      "Epoch 23/100\n",
      "30072/30072 [==============================] - 4s 128us/step - loss: 2.2969 - accuracy: 0.3017 - val_loss: 33.2642 - val_accuracy: 0.0173\n",
      "Epoch 24/100\n",
      "30072/30072 [==============================] - 4s 127us/step - loss: 2.2561 - accuracy: 0.3137 - val_loss: 33.2608 - val_accuracy: 0.0220\n",
      "Epoch 25/100\n",
      "30072/30072 [==============================] - 4s 128us/step - loss: 2.2237 - accuracy: 0.3201 - val_loss: 24.7202 - val_accuracy: 0.0228\n",
      "Epoch 26/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 2.1741 - accuracy: 0.3312 - val_loss: 27.7098 - val_accuracy: 0.0128\n",
      "Epoch 27/100\n",
      "30072/30072 [==============================] - 4s 131us/step - loss: 2.1249 - accuracy: 0.3388 - val_loss: 38.5634 - val_accuracy: 0.0058\n",
      "Epoch 28/100\n",
      "30072/30072 [==============================] - 4s 134us/step - loss: 2.0849 - accuracy: 0.3495 - val_loss: 23.1998 - val_accuracy: 0.0298\n",
      "Epoch 29/100\n",
      "30072/30072 [==============================] - 4s 135us/step - loss: 2.0583 - accuracy: 0.3528 - val_loss: 38.5814 - val_accuracy: 0.0179\n",
      "Epoch 30/100\n",
      "30072/30072 [==============================] - 4s 139us/step - loss: 2.0255 - accuracy: 0.3626 - val_loss: 34.0691 - val_accuracy: 0.0138\n",
      "Epoch 31/100\n",
      "30072/30072 [==============================] - 4s 142us/step - loss: 1.9648 - accuracy: 0.3771 - val_loss: 42.8409 - val_accuracy: 0.0187\n",
      "Epoch 32/100\n",
      "30072/30072 [==============================] - 4s 140us/step - loss: 1.9573 - accuracy: 0.3809 - val_loss: 36.9548 - val_accuracy: 0.0430\n",
      "Epoch 33/100\n",
      "30072/30072 [==============================] - 5s 156us/step - loss: 1.9382 - accuracy: 0.3841 - val_loss: 28.7868 - val_accuracy: 0.0273\n",
      "Epoch 34/100\n",
      "30072/30072 [==============================] - 5s 158us/step - loss: 1.8660 - accuracy: 0.4023 - val_loss: 38.9331 - val_accuracy: 0.0115\n",
      "Epoch 35/100\n",
      "30072/30072 [==============================] - 5s 167us/step - loss: 1.8448 - accuracy: 0.4075 - val_loss: 37.5100 - val_accuracy: 0.0117\n",
      "Epoch 36/100\n",
      "30072/30072 [==============================] - 5s 169us/step - loss: 1.8251 - accuracy: 0.4152 - val_loss: 30.6347 - val_accuracy: 0.0183\n",
      "Epoch 37/100\n",
      "30072/30072 [==============================] - 5s 161us/step - loss: 1.8022 - accuracy: 0.4194 - val_loss: 39.1753 - val_accuracy: 0.0285\n",
      "Epoch 38/100\n",
      "30072/30072 [==============================] - 5s 151us/step - loss: 1.7300 - accuracy: 0.4355 - val_loss: 29.2674 - val_accuracy: 0.0096\n",
      "Epoch 39/100\n",
      "30072/30072 [==============================] - 4s 135us/step - loss: 1.7261 - accuracy: 0.4377 - val_loss: 52.6806 - val_accuracy: 0.0200\n",
      "Epoch 40/100\n",
      "30072/30072 [==============================] - 4s 126us/step - loss: 1.6997 - accuracy: 0.4449 - val_loss: 50.0917 - val_accuracy: 0.0139\n",
      "Epoch 41/100\n",
      "30072/30072 [==============================] - 4s 123us/step - loss: 1.6723 - accuracy: 0.4537 - val_loss: 36.0970 - val_accuracy: 0.0175\n",
      "Epoch 42/100\n",
      "30072/30072 [==============================] - 4s 122us/step - loss: 1.6404 - accuracy: 0.4626 - val_loss: 30.2443 - val_accuracy: 0.0209\n",
      "Epoch 43/100\n",
      "30072/30072 [==============================] - 4s 124us/step - loss: 1.6115 - accuracy: 0.4711 - val_loss: 38.1577 - val_accuracy: 0.0222\n",
      "Epoch 44/100\n",
      "30072/30072 [==============================] - 4s 122us/step - loss: 1.6004 - accuracy: 0.4709 - val_loss: 36.7621 - val_accuracy: 0.0136\n",
      "Epoch 45/100\n",
      "30072/30072 [==============================] - 4s 122us/step - loss: 1.5613 - accuracy: 0.4811 - val_loss: 27.6939 - val_accuracy: 0.0198\n",
      "Epoch 46/100\n",
      "30072/30072 [==============================] - 4s 130us/step - loss: 1.5426 - accuracy: 0.4890 - val_loss: 37.6588 - val_accuracy: 0.0151\n",
      "Epoch 47/100\n",
      "30072/30072 [==============================] - 4s 126us/step - loss: 1.5168 - accuracy: 0.4931 - val_loss: 38.1738 - val_accuracy: 0.0286\n",
      "Epoch 48/100\n",
      "30072/30072 [==============================] - 4s 127us/step - loss: 1.4721 - accuracy: 0.5065 - val_loss: 50.1165 - val_accuracy: 0.0243\n",
      "Epoch 49/100\n",
      "30072/30072 [==============================] - 4s 127us/step - loss: 1.4667 - accuracy: 0.5086 - val_loss: 38.7997 - val_accuracy: 0.0122\n",
      "Epoch 50/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 1.4710 - accuracy: 0.5086 - val_loss: 32.4085 - val_accuracy: 0.0205\n",
      "Epoch 51/100\n",
      "30072/30072 [==============================] - 4s 128us/step - loss: 1.4302 - accuracy: 0.5183 - val_loss: 30.8077 - val_accuracy: 0.0177\n",
      "Epoch 52/100\n",
      "30072/30072 [==============================] - 4s 146us/step - loss: 1.4200 - accuracy: 0.5187 - val_loss: 33.5883 - val_accuracy: 0.0188\n",
      "Epoch 53/100\n",
      "30072/30072 [==============================] - 4s 139us/step - loss: 1.4153 - accuracy: 0.5228 - val_loss: 69.1950 - val_accuracy: 0.0068\n",
      "Epoch 54/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 1.3599 - accuracy: 0.5390 - val_loss: 47.0137 - val_accuracy: 0.0147\n",
      "Epoch 55/100\n",
      "30072/30072 [==============================] - 4s 122us/step - loss: 1.3637 - accuracy: 0.5336 - val_loss: 49.8515 - val_accuracy: 0.0119\n",
      "Epoch 56/100\n",
      "30072/30072 [==============================] - 4s 125us/step - loss: 1.3554 - accuracy: 0.5379 - val_loss: 35.2128 - val_accuracy: 0.0124\n",
      "Epoch 57/100\n",
      "30072/30072 [==============================] - 4s 134us/step - loss: 1.3046 - accuracy: 0.5543 - val_loss: 32.4525 - val_accuracy: 0.0162\n",
      "Epoch 58/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 1.3002 - accuracy: 0.5571 - val_loss: 72.1005 - val_accuracy: 0.0051\n",
      "Epoch 59/100\n",
      "30072/30072 [==============================] - 4s 127us/step - loss: 1.2804 - accuracy: 0.5627 - val_loss: 48.0088 - val_accuracy: 0.0139\n",
      "Epoch 60/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 1.2938 - accuracy: 0.5571 - val_loss: 37.0386 - val_accuracy: 0.0213\n",
      "Epoch 61/100\n",
      "30072/30072 [==============================] - 4s 128us/step - loss: 1.2693 - accuracy: 0.5647 - val_loss: 41.2546 - val_accuracy: 0.0147\n",
      "Epoch 62/100\n",
      "30072/30072 [==============================] - 4s 130us/step - loss: 1.2558 - accuracy: 0.5668 - val_loss: 29.3491 - val_accuracy: 0.0228\n",
      "Epoch 63/100\n",
      "30072/30072 [==============================] - 4s 132us/step - loss: 1.2605 - accuracy: 0.5688 - val_loss: 35.2933 - val_accuracy: 0.0126\n",
      "Epoch 64/100\n",
      "30072/30072 [==============================] - 4s 130us/step - loss: 1.2285 - accuracy: 0.5766 - val_loss: 50.3598 - val_accuracy: 0.0124\n",
      "Epoch 65/100\n",
      "30072/30072 [==============================] - 4s 130us/step - loss: 1.2442 - accuracy: 0.5744 - val_loss: 37.2951 - val_accuracy: 0.0064\n",
      "Epoch 66/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 1.1943 - accuracy: 0.5841 - val_loss: 37.4054 - val_accuracy: 0.0122\n",
      "Epoch 67/100\n",
      "30072/30072 [==============================] - 4s 130us/step - loss: 1.2263 - accuracy: 0.5755 - val_loss: 45.5675 - val_accuracy: 0.0234\n",
      "Epoch 68/100\n",
      "30072/30072 [==============================] - 4s 133us/step - loss: 1.1778 - accuracy: 0.5927 - val_loss: 51.3301 - val_accuracy: 0.0092\n",
      "Epoch 69/100\n",
      "30072/30072 [==============================] - 4s 131us/step - loss: 1.1590 - accuracy: 0.5974 - val_loss: 42.1352 - val_accuracy: 0.0168\n",
      "Epoch 70/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 1.1884 - accuracy: 0.5905 - val_loss: 41.6233 - val_accuracy: 0.0175\n",
      "Epoch 71/100\n",
      "30072/30072 [==============================] - 4s 130us/step - loss: 1.1252 - accuracy: 0.6090 - val_loss: 64.3301 - val_accuracy: 0.0036\n",
      "Epoch 72/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 1.1385 - accuracy: 0.6045 - val_loss: 69.8670 - val_accuracy: 0.0168\n",
      "Epoch 73/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 1.1428 - accuracy: 0.5999 - val_loss: 36.8301 - val_accuracy: 0.0164\n",
      "Epoch 74/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 1.1094 - accuracy: 0.6165 - val_loss: 36.2069 - val_accuracy: 0.0207\n",
      "Epoch 75/100\n",
      "30072/30072 [==============================] - 4s 128us/step - loss: 1.0889 - accuracy: 0.6168 - val_loss: 34.6329 - val_accuracy: 0.0360\n",
      "Epoch 76/100\n",
      "30072/30072 [==============================] - 4s 128us/step - loss: 1.1073 - accuracy: 0.6144 - val_loss: 47.9743 - val_accuracy: 0.0147\n",
      "Epoch 77/100\n",
      "30072/30072 [==============================] - 4s 132us/step - loss: 1.0980 - accuracy: 0.6185 - val_loss: 45.3830 - val_accuracy: 0.0298\n",
      "Epoch 78/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 1.1011 - accuracy: 0.6170 - val_loss: 35.5145 - val_accuracy: 0.0139\n",
      "Epoch 79/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 1.0732 - accuracy: 0.6264 - val_loss: 42.4350 - val_accuracy: 0.0360\n",
      "Epoch 80/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 1.0636 - accuracy: 0.6254 - val_loss: 38.5292 - val_accuracy: 0.0226\n",
      "Epoch 81/100\n",
      "30072/30072 [==============================] - 4s 131us/step - loss: 1.0225 - accuracy: 0.6404 - val_loss: 40.2920 - val_accuracy: 0.0141\n",
      "Epoch 82/100\n",
      "30072/30072 [==============================] - 4s 130us/step - loss: 1.0397 - accuracy: 0.6339 - val_loss: 46.7502 - val_accuracy: 0.0126\n",
      "Epoch 83/100\n",
      "30072/30072 [==============================] - 4s 130us/step - loss: 1.0205 - accuracy: 0.6407 - val_loss: 46.1122 - val_accuracy: 0.0109\n",
      "Epoch 84/100\n",
      "30072/30072 [==============================] - 4s 128us/step - loss: 1.0325 - accuracy: 0.6385 - val_loss: 50.8635 - val_accuracy: 0.0081\n",
      "Epoch 85/100\n",
      "30072/30072 [==============================] - 4s 130us/step - loss: 0.9949 - accuracy: 0.6522 - val_loss: 45.1534 - val_accuracy: 0.0232\n",
      "Epoch 86/100\n",
      "30072/30072 [==============================] - 4s 127us/step - loss: 1.0219 - accuracy: 0.6429 - val_loss: 52.1729 - val_accuracy: 0.0087\n",
      "Epoch 87/100\n",
      "30072/30072 [==============================] - 4s 125us/step - loss: 0.9919 - accuracy: 0.6500 - val_loss: 48.2276 - val_accuracy: 0.0177\n",
      "Epoch 88/100\n",
      "30072/30072 [==============================] - 4s 126us/step - loss: 0.9902 - accuracy: 0.6521 - val_loss: 33.4139 - val_accuracy: 0.0239\n",
      "Epoch 89/100\n",
      "30072/30072 [==============================] - 4s 125us/step - loss: 0.9863 - accuracy: 0.6543 - val_loss: 43.7286 - val_accuracy: 0.0109\n",
      "Epoch 90/100\n",
      "30072/30072 [==============================] - 4s 128us/step - loss: 0.9623 - accuracy: 0.6575 - val_loss: 45.1210 - val_accuracy: 0.0138\n",
      "Epoch 91/100\n",
      "30072/30072 [==============================] - 4s 128us/step - loss: 0.9575 - accuracy: 0.6611 - val_loss: 46.6610 - val_accuracy: 0.0058\n",
      "Epoch 92/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 0.9779 - accuracy: 0.6564 - val_loss: 42.3054 - val_accuracy: 0.0177\n",
      "Epoch 93/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 0.9371 - accuracy: 0.6681 - val_loss: 40.6134 - val_accuracy: 0.0085\n",
      "Epoch 94/100\n",
      "30072/30072 [==============================] - 4s 127us/step - loss: 0.9411 - accuracy: 0.6656 - val_loss: 41.2976 - val_accuracy: 0.0183\n",
      "Epoch 95/100\n",
      "30072/30072 [==============================] - 4s 128us/step - loss: 0.9286 - accuracy: 0.6699 - val_loss: 56.3526 - val_accuracy: 0.0092\n",
      "Epoch 96/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 0.9240 - accuracy: 0.6706 - val_loss: 43.4022 - val_accuracy: 0.0126\n",
      "Epoch 97/100\n",
      "30072/30072 [==============================] - 4s 128us/step - loss: 0.9428 - accuracy: 0.6679 - val_loss: 34.0407 - val_accuracy: 0.0234\n",
      "Epoch 98/100\n",
      "30072/30072 [==============================] - 4s 132us/step - loss: 0.9171 - accuracy: 0.6736 - val_loss: 48.8494 - val_accuracy: 0.0141\n",
      "Epoch 99/100\n",
      "30072/30072 [==============================] - 4s 130us/step - loss: 0.9194 - accuracy: 0.6774 - val_loss: 54.2120 - val_accuracy: 0.0132\n",
      "Epoch 100/100\n",
      "30072/30072 [==============================] - 4s 129us/step - loss: 0.9156 - accuracy: 0.6758 - val_loss: 41.0606 - val_accuracy: 0.0147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff5ee938a90>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(input_data, label, epochs=epochs, batch_size=batch_size, validation_split=0.15, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
